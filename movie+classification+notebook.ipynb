{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXxGTgJz152A"
   },
   "source": [
    "## Stanford Sentiment Treebank - Movie Review Classification Competition\n",
    "The SST-2 dataset is a benchmark dataset for sentiment analysis. It contains a collection of movie reviews with a binary label indicating whether the review is positive or negative. There are approximately 8,000 reviews in total, which are split into training and test sets. \n",
    "\n",
    "Building a predictive model using the SST-2 dataset can be practically useful for a variety of applications, such as:\n",
    "\n",
    "1. Product/Service Performance: Companies and producers can use such models to automatically classify reviews of their products or services as positive or negative, allowing them to identify areas for improvement and respond to customer feedback.\n",
    "\n",
    "2. Marketing and Investment: Market researchers and directors/producers can use such models to analyze customer sentiment towards specific movies or brands, helping them to identify market trends.\n",
    "\n",
    "3. Personalization: Companies can use such models to identify consumers' preference and sentiment toward a certain movie or category of movies along with user information in order to provide personalized streaming services and high quality recommendation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5gSrVJwp3E9H"
   },
   "source": [
    "## 1. Get data in and set up X_train, X_test, y_train objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLTIaMB3ChSW"
   },
   "outputs": [],
   "source": [
    "#install aimodelshare library\n",
    "! pip install aimodelshare==0.0.189"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3PiJXBhC5y-",
    "outputId": "7e5316a3-10d9-4657-cf57-352847216a52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading [=============================================>   ]\n",
      "\n",
      "Data downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Get competition data\n",
    "from aimodelshare import download_data\n",
    "download_data('public.ecr.aws/y2e2a1d6/sst2_competition_data-repository:latest') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jT0qFCZFNzHq",
    "outputId": "33bf001c-3e8d-4d89-c9e1-eff2a4a48eef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    The Rock is destined to be the 21st Century 's...\n",
       "1    The gorgeously elaborate continuation of `` Th...\n",
       "2    Singer/composer Bryan Adams contributes a slew...\n",
       "3                 Yet the act is still charming here .\n",
       "4    Whether or not you 're enlightened by any of D...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up X_train, X_test, and y_train_labels objects\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "X_train=pd.read_csv(\"sst2_competition_data/X_train.csv\", squeeze=True)\n",
    "X_test=pd.read_csv(\"sst2_competition_data/X_test.csv\", squeeze=True)\n",
    "\n",
    "y_train_labels=pd.read_csv(\"sst2_competition_data/y_train_labels.csv\", squeeze=True)\n",
    "\n",
    "# ohe encode Y data\n",
    "y_train = pd.get_dummies(y_train_labels)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "58Rp3jdZBocJ",
    "outputId": "c5e19be2-2473-4c78-d76c-a8ff64c28646"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-064c6236-5297-40a6-bcf6-9fcd24af94ef\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Negative</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-064c6236-5297-40a6-bcf6-9fcd24af94ef')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-064c6236-5297-40a6-bcf6-9fcd24af94ef button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-064c6236-5297-40a6-bcf6-9fcd24af94ef');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Negative  Positive\n",
       "0         0         1\n",
       "1         0         1\n",
       "2         0         1\n",
       "3         0         1\n",
       "4         0         1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NuSmcD94Cccn",
    "outputId": "2d2633f9-fc80-4504-deda-7427948f46f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6920, 1821)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEzPoXPj3V7u"
   },
   "source": [
    "##2.   Preprocess data using keras tokenizer / Write and Save Preprocessor function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "16QV9Y9TC3B3",
    "outputId": "78edf69d-349d-4b70-c57d-2f29d409493f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6920, 40)\n",
      "(1821, 40)\n"
     ]
    }
   ],
   "source": [
    "# This preprocessor function makes use of the tf.keras tokenizer\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Build vocabulary from training text data\n",
    "tokenizer = Tokenizer(num_words=10000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# preprocessor tokenizes words and makes sure all documents have the same length\n",
    "def preprocessor(data, maxlen=40, max_words=10000):\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(data)\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    X = pad_sequences(sequences, maxlen=maxlen)\n",
    "\n",
    "    return X\n",
    "\n",
    "print(preprocessor(X_train).shape)\n",
    "print(preprocessor(X_test).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmJAnmO-5AcU"
   },
   "source": [
    "#### Save preprocessor function to local \"preprocessor.zip\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4VGacc0LDaMA",
    "outputId": "29f0c4bf-586f-4572-c3a7-b6730aafafe1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your preprocessor is now saved to 'preprocessor.zip'\n"
     ]
    }
   ],
   "source": [
    "import aimodelshare as ai\n",
    "ai.export_preprocessor(preprocessor,\"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X52kECL43b-O"
   },
   "source": [
    "## 3. Fit model on preprocessed data and save preprocessor function and model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_CtuNlbEmnb"
   },
   "source": [
    "### Conv1d with Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCbBf8j9ClYl",
    "outputId": "d07b6be1-1047-45e4-8d10-710228b1a2e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_25 (Embedding)    (None, 40, 16)            160000    \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 36, 64)            5184      \n",
      "                                                                 \n",
      " flatten_22 (Flatten)        (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 2)                 4610      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 169,794\n",
      "Trainable params: 169,794\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "173/173 [==============================] - 2s 8ms/step - loss: 0.6575 - acc: 0.6161 - val_loss: 0.8722 - val_acc: 0.1496\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 1s 7ms/step - loss: 0.4986 - acc: 0.7513 - val_loss: 0.5751 - val_acc: 0.7478\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.3299 - acc: 0.8562 - val_loss: 0.5188 - val_acc: 0.7789\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 1s 7ms/step - loss: 0.2450 - acc: 0.8981 - val_loss: 0.6361 - val_acc: 0.7175\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.1871 - acc: 0.9245 - val_loss: 0.6805 - val_acc: 0.7153\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.1436 - acc: 0.9417 - val_loss: 0.7542 - val_acc: 0.7088\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 0.1124 - acc: 0.9534 - val_loss: 0.6273 - val_acc: 0.7579\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 2s 10ms/step - loss: 0.0841 - acc: 0.9689 - val_loss: 0.7030 - val_acc: 0.7471\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 2s 11ms/step - loss: 0.0632 - acc: 0.9760 - val_loss: 0.6488 - val_acc: 0.7818\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 2s 13ms/step - loss: 0.0450 - acc: 0.9837 - val_loss: 1.1451 - val_acc: 0.6842\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 16, input_length=40))\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOWBa8Cv5LdL"
   },
   "source": [
    "#### Save model to local \".onnx\" file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "pEhvnRiQDlY5"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHWkAzvX3m8O"
   },
   "source": [
    "#### Generate predictions from X_test data and submit model to competition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtgkM02MDpkO",
    "outputId": "6599655e-11c0-47dc-8b5d-ff27f5409783"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Modelshare Username:··········\n",
      "AI Modelshare Password:··········\n",
      "AI Model Share login credentials set successfully.\n"
     ]
    }
   ],
   "source": [
    "#Set credentials using modelshare.org username/password\n",
    "\n",
    "from aimodelshare.aws import set_credentials\n",
    "    \n",
    "apiurl=\"https://rlxjxnoql9.execute-api.us-east-1.amazonaws.com/prod/m\" #This is the unique rest api that powers this specific Playground\n",
    "\n",
    "set_credentials(apiurl=apiurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "fKNGSww8EGgi"
   },
   "outputs": [],
   "source": [
    "#Instantiate Competition\n",
    "\n",
    "mycompetition= ai.Competition(apiurl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Ql4wksyEUnP",
    "outputId": "50553289-19ac-4293-a954-7b741ce7f202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 8ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 257\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "#Submit Model 1: \n",
    "\n",
    "#-- Generate predicted y values (Model 1)\n",
    "#Note: Keras predict returns the predicted column index location for classification models\n",
    "prediction_column_index=model.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 1 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaYLS6vzK8UD"
   },
   "source": [
    "#### Model Performance\n",
    "Accuracy: 0.7782656422\n",
    "\n",
    "F-1 score: 0.7755062704\n",
    "\n",
    "Precision: 0.7929332887\n",
    "\n",
    "Recall: 0.7783882784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThL7rFhm37xl"
   },
   "source": [
    "Conv1d with Embedding v.3\n",
    "- cut movie review after 100 words instead of 40\n",
    "- learn a feature vector of size 100 instead of 40\n",
    "\n",
    "It does not help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C87UCTWi38UR"
   },
   "source": [
    "#### Model Performance\n",
    "Accuracy: 0.7771679473\n",
    "\n",
    "F-1 score: 0.7744502214\n",
    "\n",
    "Precision: 0.7914783666\n",
    "\n",
    "Recall: 0.7772893773"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8iavxDgLMt9"
   },
   "source": [
    "### Conv1d with Embedding v.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2EJ-Xk5YLL9-",
    "outputId": "223bde0d-6506-4135-9c4a-febca406a809"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 40, 16)            160000    \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 36, 128)           10368     \n",
      "                                                                 \n",
      " global_max_pooling1d_1 (Glo  (None, 128)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 32)                4128      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,562\n",
      "Trainable params: 174,562\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.6519 - acc: 0.6167 - val_loss: 0.7793 - val_acc: 0.3714\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.4894 - acc: 0.7664 - val_loss: 0.5765 - val_acc: 0.7168\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.3293 - acc: 0.8622 - val_loss: 0.6741 - val_acc: 0.6756\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.2381 - acc: 0.9059 - val_loss: 0.8345 - val_acc: 0.6344\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1785 - acc: 0.9290 - val_loss: 0.7304 - val_acc: 0.7045\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1341 - acc: 0.9501 - val_loss: 0.9343 - val_acc: 0.6749\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 2s 14ms/step - loss: 0.0940 - acc: 0.9669 - val_loss: 1.0141 - val_acc: 0.6886\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 3s 20ms/step - loss: 0.0674 - acc: 0.9799 - val_loss: 1.1111 - val_acc: 0.6864\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 3s 18ms/step - loss: 0.0460 - acc: 0.9863 - val_loss: 0.8975 - val_acc: 0.7666\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 2s 13ms/step - loss: 0.0298 - acc: 0.9917 - val_loss: 1.1511 - val_acc: 0.7377\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Embedding, Flatten, Conv1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(10000, 16, input_length=40))\n",
    "model1.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model1.add(GlobalMaxPooling1D())\n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(32, activation='relu'))\n",
    "model1.add(Dense(2, activation='softmax'))\n",
    "model1.summary()\n",
    "\n",
    "model1.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "history = model1.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "V8bpf2tJLXxN"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model1, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model1.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OADyaMYzLfwG",
    "outputId": "36853324-c0d7-44e8-e1e4-e4acb1133a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 238\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "prediction_column_index=model.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "mycompetition.submit_model(model_filepath = \"model1.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGR0ickVgrNN"
   },
   "source": [
    "#### Model Performance (no obvious improvement)\n",
    "Accuracy: 0.7782656422\n",
    "\n",
    "F-1 score: 0.7755062704\n",
    "\n",
    "Precision: 0.7929332887\n",
    "\n",
    "Recall: 0.7783882784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bwNKs0wP4r5s"
   },
   "source": [
    "### LSTM with Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgSs5PAtPCZH",
    "outputId": "1c2650f0-8cef-4ce4-ff5a-5ad2f383ef90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173/173 [==============================] - 16s 62ms/step - loss: 0.6516 - acc: 0.6190 - val_loss: 0.7876 - val_acc: 0.3512\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 8s 46ms/step - loss: 0.5058 - acc: 0.7527 - val_loss: 0.6688 - val_acc: 0.7095\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 11s 64ms/step - loss: 0.3837 - acc: 0.8306 - val_loss: 0.6269 - val_acc: 0.6987\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 6s 36ms/step - loss: 0.3209 - acc: 0.8633 - val_loss: 0.6373 - val_acc: 0.7197\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 9s 52ms/step - loss: 0.2661 - acc: 0.8873 - val_loss: 0.5830 - val_acc: 0.7587\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 0.2379 - acc: 0.9014 - val_loss: 0.6056 - val_acc: 0.7471\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 7s 38ms/step - loss: 0.2039 - acc: 0.9174 - val_loss: 0.5424 - val_acc: 0.7681\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 9s 54ms/step - loss: 0.1805 - acc: 0.9259 - val_loss: 0.6470 - val_acc: 0.7601\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 6s 35ms/step - loss: 0.1642 - acc: 0.9341 - val_loss: 0.6753 - val_acc: 0.7442\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 8s 46ms/step - loss: 0.1507 - acc: 0.9424 - val_loss: 0.8599 - val_acc: 0.7016\n"
     ]
    }
   ],
   "source": [
    "# Train and submit model 2 using same preprocessor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(10000, 16, input_length=40))\n",
    "model2.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
    "model2.add(LSTM(32, dropout=0.2))\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model2.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "aIdmSpYVPYAw"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model2, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model2.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nszPPrfwPlUk",
    "outputId": "91b7db19-f8f2-4117-b432-0d407666f08e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 5s 45ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 260\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "#Submit Model 2: \n",
    "\n",
    "#-- Generate predicted y values (Model 2)\n",
    "prediction_column_index=model2.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 2 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model2.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pNRhKDpoiG0-"
   },
   "source": [
    "#### Model Performance\n",
    "Accuracy: 0.8166849616\n",
    "\n",
    "F-1 score: 0.8164859515\n",
    "\n",
    "Precision: 0.8179831567\n",
    "\n",
    "Recall: 0.8166497976\n",
    "\n",
    "LSTM with Embedding performs better than models with Conv1d layers and models with pretrained weights, so I will continue improving the predictive power based off the LSTMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvpT30EJ5GyF"
   },
   "source": [
    "LSTM with Embedding v.2\n",
    "- cut movie review after 100 words instead of 40\n",
    "- learn a feature vector of size 100 instead of 40\n",
    "\n",
    "It does not help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alQV4pSI5Gn6"
   },
   "source": [
    "#### Model Performance\n",
    "Accuracy: 0.7947310648\n",
    "\n",
    "F-1 score: 0.7939524786\n",
    "\n",
    "Precision: 0.7994057409\n",
    "\n",
    "Recall: 0.7947994987"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHS7K9gwi_ks"
   },
   "source": [
    "### Deeper Stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_n5dHqEdjDeW",
    "outputId": "8ec9de6e-f6dd-4687-c3d1-2d8536ea6f3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173/173 [==============================] - 24s 97ms/step - loss: 0.6570 - acc: 0.6250 - val_loss: 0.7190 - val_acc: 0.5665\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 16s 91ms/step - loss: 0.4994 - acc: 0.7567 - val_loss: 0.8489 - val_acc: 0.5412\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 16s 90ms/step - loss: 0.3773 - acc: 0.8389 - val_loss: 0.9081 - val_acc: 0.5058\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 14s 84ms/step - loss: 0.3048 - acc: 0.8743 - val_loss: 0.7037 - val_acc: 0.6850\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 14s 78ms/step - loss: 0.2551 - acc: 0.9012 - val_loss: 0.6639 - val_acc: 0.7175\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 16s 94ms/step - loss: 0.2135 - acc: 0.9167 - val_loss: 0.6656 - val_acc: 0.7348\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 20s 113ms/step - loss: 0.1835 - acc: 0.9258 - val_loss: 0.6517 - val_acc: 0.7652\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 16s 91ms/step - loss: 0.1591 - acc: 0.9371 - val_loss: 0.6062 - val_acc: 0.7803\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 15s 88ms/step - loss: 0.1440 - acc: 0.9433 - val_loss: 0.7876 - val_acc: 0.6965\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 13s 75ms/step - loss: 0.1290 - acc: 0.9480 - val_loss: 0.6919 - val_acc: 0.7681\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Embedding(10000, 32, input_length=40))\n",
    "model4.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
    "model4.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
    "model4.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
    "model4.add(LSTM(32, dropout=0.2))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model4.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model4.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "2HZj3ZK5jynp"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model4, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model4.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luM9sSkVjyLy",
    "outputId": "1cd19920-728f-4b17-9a9d-9794b753c307"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 5s 33ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 241\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "prediction_column_index=model4.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "mycompetition.submit_model(model_filepath = \"model4.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nblmg-xLlROd"
   },
   "source": [
    "#### Model Performance (does not help)\n",
    "Accuracy: 0.7914379802\n",
    "\n",
    "F-1 score: 0.7906182863\n",
    "\n",
    "Precision: 0.7962277273\n",
    "\n",
    "Recall: 0.7915076152\n",
    "\n",
    "Having several layers of LSTMs negatively influence the predictive power of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uybE4VeShPMr"
   },
   "source": [
    "### Bidirectional LSTM with Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjUqxxZLhWk8",
    "outputId": "adfaebae-8762-4ef4-fd39-8a750a59a112"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173/173 [==============================] - 17s 39ms/step - loss: 0.6489 - acc: 0.6187 - val_loss: 0.8465 - val_acc: 0.2666\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 8s 44ms/step - loss: 0.4684 - acc: 0.7803 - val_loss: 0.4642 - val_acc: 0.8042\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 8s 46ms/step - loss: 0.3353 - acc: 0.8582 - val_loss: 0.4056 - val_acc: 0.8345\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 6s 33ms/step - loss: 0.2651 - acc: 0.8914 - val_loss: 0.5050 - val_acc: 0.7984\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 9s 53ms/step - loss: 0.2184 - acc: 0.9133 - val_loss: 0.5625 - val_acc: 0.7652\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 7s 39ms/step - loss: 0.1875 - acc: 0.9283 - val_loss: 0.7364 - val_acc: 0.6864\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 6s 32ms/step - loss: 0.1520 - acc: 0.9442 - val_loss: 0.6203 - val_acc: 0.7233\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 10s 57ms/step - loss: 0.1380 - acc: 0.9483 - val_loss: 0.6660 - val_acc: 0.7442\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 5s 31ms/step - loss: 0.1160 - acc: 0.9585 - val_loss: 0.7859 - val_acc: 0.7312\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 6s 36ms/step - loss: 0.1030 - acc: 0.9626 - val_loss: 0.7699 - val_acc: 0.7160\n"
     ]
    }
   ],
   "source": [
    "# Train and submit model 3 using same preprocessor\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten, Bidirectional\n",
    "\n",
    "model5 = Sequential()\n",
    "model5.add(Embedding(10000, 32, input_length=40))\n",
    "model5.add(Bidirectional(LSTM(32, dropout=0.2)))\n",
    "model5.add(Flatten())\n",
    "model5.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model5.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "history = model5.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "KCu6bnedhWav"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model5, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model5.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wB8ma7k1hzeb",
    "outputId": "f0c0f511-4ed4-41ce-810b-7093d2dc8181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 3s 18ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 244\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "prediction_column_index=model5.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "mycompetition.submit_model(model_filepath = \"model5.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsGcsdVSl8qr"
   },
   "source": [
    "#### Model Performance \n",
    "Accuracy: 0.8090010977\n",
    "\n",
    "F-1 score: 0.8089824544\n",
    "\n",
    "Precision: 0.8091470177\n",
    "\n",
    "Recall: 0.8090129169\n",
    "\n",
    "Changing from LSTM to bidirectional LSTM does not help with predicting the sentiment result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQGa-KO2GTXN"
   },
   "source": [
    "### Transfer Learning with glove embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dshp0HoEAgI1",
    "outputId": "751410c5-43c6-4873-ec83-65c2510f1521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-17 00:41:42--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
      "--2023-04-17 00:41:42--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
      "--2023-04-17 00:41:42--  https://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182753 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  5.11MB/s    in 2m 39s  \n",
      "\n",
      "2023-04-17 00:44:23 (5.16 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What if we wanted to use a matrix of pretrained embeddings?  Same as transfer learning before, but now we are importing a pretrained Embedding matrix:\n",
    "# Download Glove embedding matrix weights (Might take 10 mins or so!)\n",
    "! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_3Cye4YcGfuE",
    "outputId": "58b09357-6d69-4b72-fbdf-1e0ba64e5ab6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  glove.6B.zip\n",
      "  inflating: glove.6B.100d.txt       \n",
      "  inflating: glove.6B.200d.txt       \n",
      "  inflating: glove.6B.300d.txt       \n",
      "  inflating: glove.6B.50d.txt        \n"
     ]
    }
   ],
   "source": [
    "! unzip glove.6B.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZEuaRfxpGhql",
    "outputId": "fd7f21b1-4461-44cb-c674-ed691157d6f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400001 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Extract embedding data\n",
    "import os\n",
    "glove_dir = os.getcwd()\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(glove_dir, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "bPfOiybxGlCA"
   },
   "outputs": [],
   "source": [
    "# Build embedding matrix\n",
    "embedding_dim = 100 # change if you use txt files with larger number of features\n",
    "max_words = 10000\n",
    "\n",
    "embedding_matrix = np.zeros((max_words, embedding_dim))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if i < max_words:\n",
    "        if embedding_vector is not None:\n",
    "            # Words not found in embedding index will be all-zeros.\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b2dO6DB-GrOz",
    "outputId": "ac098a41-35da-45d4-fe8c-08b285dc1a3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, 40, 100)           1000000   \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 4000)              0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 32)                128032    \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,128,098\n",
      "Trainable params: 1,128,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Set up same model architecture as before and then import Glove weights to Embedding layer:\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(max_words, embedding_dim, input_length=40))\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(32, activation='relu'))\n",
    "model3.add(Dense(2, activation='sigmoid'))\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wEjnIK-7GryA",
    "outputId": "2d56e5a9-d51a-4a35-e280-3739281ac385"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173/173 [==============================] - 3s 12ms/step - loss: 0.6277 - acc: 0.6398 - val_loss: 0.9767 - val_acc: 0.3483\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.5077 - acc: 0.7464 - val_loss: 0.6266 - val_acc: 0.6987\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.4202 - acc: 0.8058 - val_loss: 0.7105 - val_acc: 0.6539\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 1s 5ms/step - loss: 0.3523 - acc: 0.8461 - val_loss: 0.7628 - val_acc: 0.6525\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 1s 6ms/step - loss: 0.2829 - acc: 0.8893 - val_loss: 0.7966 - val_acc: 0.6647\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.2283 - acc: 0.9126 - val_loss: 0.9227 - val_acc: 0.6207\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1742 - acc: 0.9426 - val_loss: 0.8849 - val_acc: 0.6720\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 1s 8ms/step - loss: 0.1319 - acc: 0.9624 - val_loss: 1.0718 - val_acc: 0.6387\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0982 - acc: 0.9758 - val_loss: 0.9216 - val_acc: 0.7168\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 2s 9ms/step - loss: 0.0687 - acc: 0.9855 - val_loss: 1.3148 - val_acc: 0.6373\n"
     ]
    }
   ],
   "source": [
    "# Add weights in same manner as transfer learning and turn of trainable option before fitting model to freeze weights.\n",
    "model3.layers[0].set_weights([embedding_matrix])\n",
    "model3.layers[0].trainable = False\n",
    "\n",
    "\n",
    "\n",
    "model3.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model3.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "model3.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "FXcQJwzfrkaH"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model3, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model3.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g5WoGqHBHbXV",
    "outputId": "9d6d8ee3-ba08-4cac-f93e-b74a64be06e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 2ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 246\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "prediction_column_index=model3.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 2 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model3.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J8KmQ7lftKn7"
   },
   "source": [
    "#### Model Performance \n",
    "Accuracy: 0.7091108672\n",
    "\n",
    "F-1 score: 0.7074810644\n",
    "\n",
    "Precision: 0.7140338679\n",
    "\n",
    "Recall: 0.7091936572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dD42C1ZArLie",
    "outputId": "3ab47a99-917f-4f1b-8778-50e38e6f9751"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_22 (Embedding)    (None, 40, 100)           1000000   \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 40, 32)            17024     \n",
      "                                                                 \n",
      " lstm_34 (LSTM)              (None, 32)                8320      \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,025,410\n",
      "Trainable params: 1,025,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Flatten\n",
    "\n",
    "model6 = Sequential()\n",
    "model6.add(Embedding(10000, embedding_dim, input_length=40))\n",
    "model6.add(LSTM(32, return_sequences=True, dropout=0.2))\n",
    "model6.add(LSTM(32, dropout=0.2))\n",
    "model6.add(Flatten())\n",
    "model6.add(Dense(2, activation='softmax'))\n",
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oMLoXt2rLeK",
    "outputId": "ede22a57-186b-4d42-cdda-fa3b17f28588"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "173/173 [==============================] - 15s 65ms/step - loss: 0.6198 - acc: 0.6458 - val_loss: 0.6643 - val_acc: 0.6900\n",
      "Epoch 2/10\n",
      "173/173 [==============================] - 6s 37ms/step - loss: 0.5512 - acc: 0.7160 - val_loss: 0.7907 - val_acc: 0.5549\n",
      "Epoch 3/10\n",
      "173/173 [==============================] - 9s 53ms/step - loss: 0.5173 - acc: 0.7404 - val_loss: 0.6554 - val_acc: 0.6633\n",
      "Epoch 4/10\n",
      "173/173 [==============================] - 7s 41ms/step - loss: 0.4963 - acc: 0.7579 - val_loss: 0.5825 - val_acc: 0.7254\n",
      "Epoch 5/10\n",
      "173/173 [==============================] - 7s 43ms/step - loss: 0.4794 - acc: 0.7607 - val_loss: 0.5810 - val_acc: 0.7182\n",
      "Epoch 6/10\n",
      "173/173 [==============================] - 9s 53ms/step - loss: 0.4581 - acc: 0.7760 - val_loss: 0.5585 - val_acc: 0.7464\n",
      "Epoch 7/10\n",
      "173/173 [==============================] - 6s 37ms/step - loss: 0.4495 - acc: 0.7780 - val_loss: 0.4907 - val_acc: 0.7738\n",
      "Epoch 8/10\n",
      "173/173 [==============================] - 10s 56ms/step - loss: 0.4388 - acc: 0.7910 - val_loss: 0.6472 - val_acc: 0.6575\n",
      "Epoch 9/10\n",
      "173/173 [==============================] - 7s 40ms/step - loss: 0.4303 - acc: 0.7901 - val_loss: 0.4500 - val_acc: 0.8121\n",
      "Epoch 10/10\n",
      "173/173 [==============================] - 8s 46ms/step - loss: 0.4117 - acc: 0.8058 - val_loss: 0.4717 - val_acc: 0.7948\n"
     ]
    }
   ],
   "source": [
    "model6.layers[0].set_weights([embedding_matrix])\n",
    "model6.layers[0].trainable = False\n",
    "\n",
    "\n",
    "\n",
    "model6.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "history = model6.fit(preprocessor(X_train), y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "model6.save_weights('pre_trained_glove_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "oSrcTIQksfT3"
   },
   "outputs": [],
   "source": [
    "# Save keras model to local ONNX file\n",
    "from aimodelshare.aimsonnx import model_to_onnx\n",
    "\n",
    "onnx_model = model_to_onnx(model6, framework='keras',\n",
    "                          transfer_learning=False,\n",
    "                          deep_learning=True)\n",
    "\n",
    "with open(\"model6.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_model.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VspHulpktATV",
    "outputId": "cc4a6177-6d68-4c2d-ae0d-09873d2b7842"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 3s 20ms/step\n",
      "Insert search tags to help users find your model (optional): \n",
      "Provide any useful notes about your model (optional): \n",
      "\n",
      "Your model has been submitted as model version 249\n",
      "\n",
      "To submit code used to create this model or to view current leaderboard navigate to Model Playground: \n",
      "\n",
      " https://www.modelshare.org/detail/model:2763\n"
     ]
    }
   ],
   "source": [
    "prediction_column_index=model6.predict(preprocessor(X_test)).argmax(axis=1)\n",
    "\n",
    "# extract correct prediction labels \n",
    "prediction_labels = [y_train.columns[i] for i in prediction_column_index]\n",
    "\n",
    "# Submit Model 2 to Competition Leaderboard\n",
    "mycompetition.submit_model(model_filepath = \"model6.onnx\",\n",
    "                                 preprocessor_filepath=\"preprocessor.zip\",\n",
    "                                 prediction_submission=prediction_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qDcJRdMxuHQO"
   },
   "source": [
    "#### Model Performance \n",
    "Accuracy: 0.7848518112\n",
    "\n",
    "F-1 score: 0.7840062322\n",
    "\n",
    "Precision: 0.7895349065\n",
    "\n",
    "Recall: 0.7849214382\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "MKvPKyb7hT0h"
   },
   "outputs": [],
   "source": [
    "# Compare two or more models\n",
    "# data=mycompetition.compare_models([1, 2, 3, 4, 5, 6], verbose=1)\n",
    "# mycompetition.stylize_compare(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuzgKMQdmRkE"
   },
   "source": [
    "### Best Model\n",
    "Model with two layers of LSTMs and word embeddings outperforms others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "asfW5LYkmP1c",
    "outputId": "652086f1-b0e6-4adb-f958-42354eca2f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_7 (Embedding)     (None, 40, 16)            160000    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 40, 32)            6272      \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 32)                8320      \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 2)                 66        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,658\n",
      "Trainable params: 174,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
